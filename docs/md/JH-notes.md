[TOC]

#### 3 确定性方法

##### 3.1 简介

假定 $P\neq NP$ ，那么 NP-hard 问题在多项式时间内是不可解的

但对于实际情况下的 NP-hard 问题，是可能存在确定性算法的求解的

Insight: slightly modify the problem specification & weaken the problem constraint 缩小问题空间，扩大解空间

1.对实际中的大部分输入高效的指数复杂度算法，解决问题的子问题

2.增长速度慢的指数复杂度算法

3.不需要解出问题，只需要提供一个可行解

##### 3.2 伪多项式时间算法 Pseudo-Polynomial-Time Algorithms

###### 基本概念

integer-valued problems

 输入是一串整数

TSP 背包问题 整数规划 节点覆盖问题 均是此类问题

目的是寻找在输入规模不太大的情况下的可行算法

动态规划和背包问题 动态规划的核心就是去寻找输入问题的子问题，且我们可以利用这些子问题高效地解决原问题

此类问题的输入有两个维度，一是数的大小，二是数的个数

$Value(h)-U$ 就是限制输入数大小到 h 的 问题 U，很显然这是原问题的一个子问题

当问题 U 不是多项式问题时，问题 $Value(h)-U$ 可以是

这里需要注意，伪多项式算法的定义 TimeA(x) = O(p(lxl, Max-Int(x))) ，其中x是问题的一个实例

此类伪多项式算法遵循了第一个方法，即通过寻找问题空间中的简单子类

###### 动态规划与背包问题

状态空间的转移 DPKP算法

###### 最大流问题和Ford-Fulkerson

最大流问题和最小割问题，一组经典的对偶问题

核心是寻找增广路径，增广路径和简单路径的区别在于增广路径的方向可以任意

###### 局限

强 NP-hard 问题

TSP旅行商问题是强 NP-hard 问题，证明的关键在于将 HC 哈密顿回路问题（已知的 NP-hard 问题）规约成 输入的数是多项式的TSP 问题

##### 3.3 参数化复杂度

###### 基本概念

还是遵循第一个方法，缩小问题空间，通过参数化来划分问题空间，通常更适用于连续问题

参数化多项式时间算法的定义：

(i) A solves U, and  

(ii) there exists a polynomial p and a function f : IN $\to$ IN such that, for every  x $\in$ L,  TimeA(x) f(Par(x)) . p(lxl). 

一个好的参数应该把握特定输入的本质难度，知道那些真正使问题变难的东西

p决定了对于给定参数，算法的效率，而f决定了哪些参数会使问题易处理

###### 参数化复杂度的应用

VC 点覆盖问题

方法一：对于度大于k的点，其一定在答案集合中，而对于度小于等于k的点，可以穷举其是否包含一个m的点覆盖

方法二：分治策略，随机选一条边，对两个点导出的新图，分别考虑点覆盖问题

##### 3.4 分支与界限(Branch and Bound)

###### 基本概念

这类方法是用来解决优化问题的。它基于回溯算法——一种遍历所有可行解空间的方法。问题在于搜索空间太大了，以至于到非多项式的大小。大致思想是去加速回溯的过程，通过剪去搜索过程中一些不可能的解空间，剪枝的标准是你在遍历该解空间之前，已经可以判断该解空间不存在可行解了。

回溯算法本质上是一种深度优先搜索，分支与界限优化的本质就是缩小解空间对应树的大小

剪枝的标准需要一些预处理得到一些bound

一些经典的计算界限的方法：

approximation algorithms ？

通过退化成线性方程的松弛 ？

随机取样 ？

本地搜索 ？

启发式算法 ？

关键在于剪枝剪的好不好

###### 在MAX-SAT和TSP问题的应用

MAX-SAT简单版本：在深度优先搜索树的过程中，但凡遇到使得某一子句不成立，即可剪枝

效率取决于：使用何种搜索，建树的顺序，剪枝的标准对问题具有唯一性

TSP预处理的版本：TSP首先是哈密顿回路，然后有两个观察：对于每个节点的度都是2，然后哈密顿回路，计算值的方式就是当前所有边权加起来，然后加上构成一个哈密顿回路所缺的边数

主要的优势在于对于此类问题，有了一定输入实例的可行解

关键就在于算bound

由于没有一般的搜索策略，所以提高算法效率的方法是：一个能够给到尽可能紧的bound的好的算法；一个能高效计算每个节点的bound的算法

如果等待太久，一种可能是结束搜索，然后返回当前最优解，还有一种就是把要求改低，只要求解与最优解相差不超过百分之多少，这样剪枝的时候，当发现子树的解最优优不过百分之多少时，就可以剪枝了

NNS问题， 最近邻问题

##### 3.6 局部搜索(Local Search)

局部搜索是针对优化问题的一种算法设计方法

它的重要性在于：

- 它是高阶局部搜索，比如模拟退火算法(SA)和 禁忌搜索算法(tabu search)，的基础
- 可以更好地考虑问题复杂性，从而确定易处理的搜索优化问题的边界

局部搜索的本质就是实现一个受限制的搜索，而受限的搜索是依赖于一个叫邻域(neighborhood)的概念

Tips: $Pot(X)$是指$X$的幂集

在实际应用中，邻域的寻找通常是通过在可行解上的转移(local transformations)完成的。比如MAX-SAT问题中改变一个变量的布尔值。

局部搜索算法从一个候选解开始，[反复](https://zh.wikipedia.org/wiki/迭代)探索其[邻域](https://zh.wikipedia.org/wiki/邻域)，并移动到邻域中的最后解。所以要使用局部搜索算法必须首先在搜索空间中定义邻域。比如，在最小顶点覆盖问题中，一个覆盖的邻域可以是只改变一个顶点能够到达的另一种覆盖；在布尔可满足性问题中，一个变量赋值的邻域可以是只改变一个变量的值能到达的所有赋值。对于同一个问题可以有很多种邻域的定义。如果一个局部优化算法将邻域定义为只改变 **k** 个成分能够到达的解，那么这个算法可以称为 **k-opt**。

通常，每个候选解的邻域包含多个解。所谓**局部**搜索，就是只根据[邻域](https://zh.wikipedia.org/wiki/邻域)中的信息来决定移动方向。如果选择的是最大化[目标函数](https://zh.wikipedia.org/w/index.php?title=目标函数&action=edit&redlink=1)的解，那么这种局部搜索算法又可以叫做[爬山算法](https://zh.wikipedia.org/wiki/爬山算法)。当邻域中已经没有比当前最优的解的时候，局部搜索就困在了局部最优解。

能尽快找到全局最优解的决定因素有：初始解的选择，邻域的划分以及转移的策略

variable-depth search

KL(Neigh) Kernighan-Lin Variable-Depth Search Algorithm with respect to the neighborhood Neigh

